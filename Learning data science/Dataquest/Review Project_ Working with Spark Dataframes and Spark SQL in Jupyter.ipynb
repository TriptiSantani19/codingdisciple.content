{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this review project, we are going to focus on processing big data using Spark SQL. \n",
    "\n",
    "We'll be working with census data from 1980, 1990, 2000, 2010. The objective of this project is to learn how to use SQLContext objects in conjunction with spark/pandas dataframes, and SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "sc=pyspark.SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to creates a SQL context object named 'sqlCtx'. this class can read data from a wide range of sources.\n",
    "\n",
    "+ This includes file formats such as: .JSON, .CSV/TSV, .XML, Parquet, Amazon S3\n",
    "+ Database systems such as: MySQL, PostgreSQL\n",
    "+ Big data systems such as: Hive, Avro, Hbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlCtx = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- females: long (nullable = true)\n",
      " |-- males: long (nullable = true)\n",
      " |-- total: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Reads the json file into a dataframe\n",
    "df = sqlCtx.read.json(\"census_2010.json\")\n",
    "print(type(df))\n",
    "\n",
    "#Prints the schema of the columns\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+-------+----+\n",
      "|age|females|  males|  total|year|\n",
      "+---+-------+-------+-------+----+\n",
      "|  0|1994141|2085528|4079669|2010|\n",
      "|  1|1997991|2087350|4085341|2010|\n",
      "|  2|2000746|2088549|4089295|2010|\n",
      "|  3|2002756|2089465|4092221|2010|\n",
      "|  4|2004366|2090436|4094802|2010|\n",
      "|  5|2005925|2091803|4097728|2010|\n",
      "|  6|2007781|2093905|4101686|2010|\n",
      "|  7|2010281|2097080|4107361|2010|\n",
      "|  8|2013771|2101670|4115441|2010|\n",
      "|  9|2018603|2108014|4126617|2010|\n",
      "| 10|2023289|2114217|4137506|2010|\n",
      "| 11|2026352|2118390|4144742|2010|\n",
      "| 12|2037286|2132030|4169316|2010|\n",
      "| 13|2060100|2159943|4220043|2010|\n",
      "| 14|2089651|2195773|4285424|2010|\n",
      "| 15|2117689|2229339|4347028|2010|\n",
      "| 16|2146942|2263862|4410804|2010|\n",
      "| 17|2165852|2285295|4451147|2010|\n",
      "| 18|2168175|2285990|4454165|2010|\n",
      "| 19|2159571|2272689|4432260|2010|\n",
      "+---+-------+-------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#prints the first 20 rows\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike pandas dataframes, spark dataframes requires us to input the number of rows we want displayed in the .head() method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(age=0, females=1994141, males=2085528, total=4079669, year=2010)\n",
      "Row(age=1, females=1997991, males=2087350, total=4085341, year=2010)\n",
      "Row(age=2, females=2000746, males=2088549, total=4089295, year=2010)\n",
      "Row(age=3, females=2002756, males=2089465, total=4092221, year=2010)\n",
      "Row(age=4, females=2004366, males=2090436, total=4094802, year=2010)\n"
     ]
    }
   ],
   "source": [
    "first_five = df.head(5)[0:5]\n",
    "for element in first_five:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(age=0, females=1994141, males=2085528, total=4079669, year=2010)\n"
     ]
    }
   ],
   "source": [
    "first_one = df.head(5)[0]\n",
    "print(first_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+----+\n",
      "|age|  males|females|year|\n",
      "+---+-------+-------+----+\n",
      "|  0|2085528|1994141|2010|\n",
      "|  1|2087350|1997991|2010|\n",
      "|  2|2088549|2000746|2010|\n",
      "|  3|2089465|2002756|2010|\n",
      "|  4|2090436|2004366|2010|\n",
      "|  5|2091803|2005925|2010|\n",
      "|  6|2093905|2007781|2010|\n",
      "|  7|2097080|2010281|2010|\n",
      "|  8|2101670|2013771|2010|\n",
      "|  9|2108014|2018603|2010|\n",
      "| 10|2114217|2023289|2010|\n",
      "| 11|2118390|2026352|2010|\n",
      "| 12|2132030|2037286|2010|\n",
      "| 13|2159943|2060100|2010|\n",
      "| 14|2195773|2089651|2010|\n",
      "| 15|2229339|2117689|2010|\n",
      "| 16|2263862|2146942|2010|\n",
      "| 17|2285295|2165852|2010|\n",
      "| 18|2285990|2168175|2010|\n",
      "| 19|2272689|2159571|2010|\n",
      "+---+-------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Selecting columns from spark dataframes and display\n",
    "df.select('age', 'males', 'females', 'year').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+-------+----+\n",
      "|age|females|  males|  total|year|\n",
      "+---+-------+-------+-------+----+\n",
      "|  6|2007781|2093905|4101686|2010|\n",
      "|  7|2010281|2097080|4107361|2010|\n",
      "|  8|2013771|2101670|4115441|2010|\n",
      "|  9|2018603|2108014|4126617|2010|\n",
      "| 10|2023289|2114217|4137506|2010|\n",
      "| 11|2026352|2118390|4144742|2010|\n",
      "| 12|2037286|2132030|4169316|2010|\n",
      "| 13|2060100|2159943|4220043|2010|\n",
      "| 14|2089651|2195773|4285424|2010|\n",
      "| 15|2117689|2229339|4347028|2010|\n",
      "| 16|2146942|2263862|4410804|2010|\n",
      "| 17|2165852|2285295|4451147|2010|\n",
      "| 18|2168175|2285990|4454165|2010|\n",
      "| 19|2159571|2272689|4432260|2010|\n",
      "| 20|2151448|2259690|4411138|2010|\n",
      "| 21|2140926|2244039|4384965|2010|\n",
      "| 22|2133510|2229168|4362678|2010|\n",
      "| 23|2132897|2218195|4351092|2010|\n",
      "| 24|2135789|2208905|4344694|2010|\n",
      "| 25|2136497|2197148|4333645|2010|\n",
      "+---+-------+-------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using boolean filtering and select rows where age > 5\n",
    "five_plus = df[df['age'] > 5]\n",
    "five_plus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+-------+----+\n",
      "|age|females|  males|  total|year|\n",
      "+---+-------+-------+-------+----+\n",
      "|  0|1994141|2085528|4079669|2010|\n",
      "|  1|1997991|2087350|4085341|2010|\n",
      "|  2|2000746|2088549|4089295|2010|\n",
      "|  3|2002756|2089465|4092221|2010|\n",
      "|  4|2004366|2090436|4094802|2010|\n",
      "|  5|2005925|2091803|4097728|2010|\n",
      "|  6|2007781|2093905|4101686|2010|\n",
      "|  7|2010281|2097080|4107361|2010|\n",
      "|  8|2013771|2101670|4115441|2010|\n",
      "|  9|2018603|2108014|4126617|2010|\n",
      "| 10|2023289|2114217|4137506|2010|\n",
      "| 11|2026352|2118390|4144742|2010|\n",
      "| 12|2037286|2132030|4169316|2010|\n",
      "| 13|2060100|2159943|4220043|2010|\n",
      "| 14|2089651|2195773|4285424|2010|\n",
      "| 15|2117689|2229339|4347028|2010|\n",
      "| 16|2146942|2263862|4410804|2010|\n",
      "| 17|2165852|2285295|4451147|2010|\n",
      "| 18|2168175|2285990|4454165|2010|\n",
      "| 19|2159571|2272689|4432260|2010|\n",
      "+---+-------+-------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Shows all columns where females < males\n",
    "df[df['females'] < df['males']].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The .toPandas() method\n",
    "\n",
    "The idea is to harness speed of Spark when analyzing big data and extract only the data we are interested in.\n",
    "Then we can convert it into a pandas dataframe for heavier data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x29bfd24c198>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29bfba18ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "pandas_df = df.toPandas()\n",
    "pandas_df['total'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>females</th>\n",
       "      <th>males</th>\n",
       "      <th>total</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1994141</td>\n",
       "      <td>2085528</td>\n",
       "      <td>4079669</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1997991</td>\n",
       "      <td>2087350</td>\n",
       "      <td>4085341</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2000746</td>\n",
       "      <td>2088549</td>\n",
       "      <td>4089295</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2002756</td>\n",
       "      <td>2089465</td>\n",
       "      <td>4092221</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2004366</td>\n",
       "      <td>2090436</td>\n",
       "      <td>4094802</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  females    males    total  year\n",
       "0    0  1994141  2085528  4079669  2010\n",
       "1    1  1997991  2087350  4085341  2010\n",
       "2    2  2000746  2088549  4089295  2010\n",
       "3    3  2002756  2089465  4092221  2010\n",
       "4    4  2004366  2090436  4094802  2010"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using SQL queries with Spark\n",
    "\n",
    "SQL is extremely useful when joining multiple tables. Spark SQL allows us to combine data from various files and store the information in one table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['census2010']\n"
     ]
    }
   ],
   "source": [
    "#Register a temp table\n",
    "\n",
    "df.registerTempTable('census2010')\n",
    "tables = sqlCtx.tableNames()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q1 = \"SELECT age FROM census2010\"\n",
    "\n",
    "sqlCtx.sql(q1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|  males|females|\n",
      "+-------+-------+\n",
      "|2093905|2007781|\n",
      "|2097080|2010281|\n",
      "|2101670|2013771|\n",
      "|2108014|2018603|\n",
      "|2114217|2023289|\n",
      "|2118390|2026352|\n",
      "|2132030|2037286|\n",
      "|2159943|2060100|\n",
      "|2195773|2089651|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q2 = \"SELECT males, females FROM census2010 WHERE age > 5 AND age < 15\"\n",
    "\n",
    "sqlCtx.sql(q2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|             males|          females|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|               101|              101|\n",
      "|   mean|1520095.3168316833|1571460.287128713|\n",
      "| stddev| 818587.2080168233|748671.0493484349|\n",
      "|    min|              4612|            25673|\n",
      "|    max|           2285990|          2331572|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using describe to show basic statistics\n",
    "q3 = \"SELECT males, females FROM census2010\"\n",
    "\n",
    "sqlCtx.sql(q3).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining files with Spark SQL\n",
    "\n",
    "This is where we see the power of Spark SQL. The ability to use joins to analyze multiple tables from various files at a high speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['census2000', 'census1990', 'census2010', 'census1980']\n"
     ]
    }
   ],
   "source": [
    "#Load files into the sqlCtx object\n",
    "df = sqlCtx.read.json(\"census_2010.json\")\n",
    "df2 = sqlCtx.read.json(\"census_1980.json\")\n",
    "df3 = sqlCtx.read.json(\"census_1990.json\")\n",
    "df4 = sqlCtx.read.json(\"census_2000.json\")\n",
    "\n",
    "df.registerTempTable('census2010')\n",
    "df2.registerTempTable('census1980')\n",
    "df3.registerTempTable('census1990')\n",
    "df4.registerTempTable('census2000')\n",
    "\n",
    "#Shows the table names\n",
    "tables = sqlCtx.tableNames()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|  total|  total|\n",
      "+-------+-------+\n",
      "|4079669|3733034|\n",
      "|4085341|3825896|\n",
      "|4089295|3904845|\n",
      "|4092221|3970865|\n",
      "|4094802|4024943|\n",
      "|4097728|4068061|\n",
      "|4101686|4101204|\n",
      "|4107361|4125360|\n",
      "|4115441|4141510|\n",
      "|4126617|4150640|\n",
      "|4137506|4152174|\n",
      "|4144742|4145530|\n",
      "|4169316|4139512|\n",
      "|4220043|4138230|\n",
      "|4285424|4137982|\n",
      "|4347028|4133932|\n",
      "|4410804|4130632|\n",
      "|4451147|4111244|\n",
      "|4454165|4068058|\n",
      "|4432260|4011192|\n",
      "+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using joins with sqlCtx\n",
    "\n",
    "q4 = 'SELECT c1.total, c2.total FROM census2010 c1 INNER JOIN census2000 c2 ON c1.age = c2.age'\n",
    "\n",
    "\n",
    "sqlCtx.sql(q4).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|2010_total|2000_total|1990_total|\n",
      "+----------+----------+----------+\n",
      "| 312247116| 284594395| 254506647|\n",
      "+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using SQL aggregate functions with multiple files\n",
    "\n",
    "q5 = '''\n",
    "SELECT \n",
    "    SUM(c1.total) 2010_total, \n",
    "    SUM(c2.total) 2000_total,\n",
    "    SUM(c3.total) 1990_total\n",
    "FROM census2010 c1 \n",
    "INNER JOIN census2000 c2 ON c1.age = c2.age\n",
    "INNER JOIN census1990 c3 ON c1.age = c3.age\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "sqlCtx.sql(q5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "#### Learning Summary\n",
    "\n",
    "Concepts explored: Spark SQL, Spark Dataframes, combining data from multiple files\n",
    "\n",
    "Methods and functions used: .SQLContext(), .head(), .toPandas(), .show(), .select(), .hist(), .registerTempTable()\n",
    "\n",
    "\n",
    "The files used for this project can be found in my [GitHub repository](https://github.com/sengkchu/Dataquest-Guided-Projects-Solutions/blob/master/Review%20Project_%20Working%20with%20Spark%20Dataframes%20and%20Spark%20SQL%20in%20Jupyter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
